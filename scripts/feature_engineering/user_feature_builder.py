#!/usr/bin/env python3
"""
ç”¨æˆ·ä¸­å¿ƒç‰¹å¾å·¥ç¨‹å™¨
æ„å»ºä»¥ç”¨æˆ·ä¸ºkeyçš„ç‰¹å¾æ•°æ®é›†
"""

import sys
import pandas as pd
import numpy as np
from collections import defaultdict, Counter
import time
from tqdm import tqdm

sys.path.append('src')


class UserFeatureBuilder:
    """ç”¨æˆ·ç‰¹å¾æ„å»ºå™¨"""

    def __init__(self, time_window_days=7):
        self.time_window_days = time_window_days
        self.target_date = "2014-12-18"
        self.features = {}

    def load_data(self, sample_frac=0.1):
        """åŠ è½½æ•°æ® - ä½¿ç”¨é‡‡æ ·é¿å…å†…å­˜é—®é¢˜"""
        print(f"ğŸ“‚ åŠ è½½æ•°æ® (é‡‡æ ·ç‡: {sample_frac})")

        files = [
            "dataset/tianchi_fresh_comp_train_user_online_partA.txt",
            "dataset/tianchi_fresh_comp_train_user_online_partB.txt"
        ]

        columns = ["user_id", "item_id", "behavior_type", "user_geohash", "item_category", "time"]

        # æ—¶é—´çª—å£è¿‡æ»¤
        target_dates = []
        base_date = pd.to_datetime("2014-12-18")
        for i in range(self.time_window_days):
            date = base_date - pd.Timedelta(days=i+1)
            target_dates.append(date.strftime("%Y-%m-%d"))

        print(f"  ğŸ¯ æ—¶é—´çª—å£: {target_dates[-1]} åˆ° {target_dates[0]}")

        dfs = []
        for file_path in tqdm(files, desc="ğŸ“ åŠ è½½æ–‡ä»¶"):
            print(f"  æ­£åœ¨åŠ è½½ {file_path}")

            # åˆ†å—è¯»å–å¹¶é‡‡æ ·
            chunk_reader = pd.read_csv(file_path, sep="\t", names=columns, chunksize=1000000)

            file_chunks = []
            for chunk in chunk_reader:
                # æ—¶é—´è¿‡æ»¤
                chunk = chunk[chunk["time"].str.startswith(tuple(target_dates))]

                if len(chunk) > 0 and sample_frac < 1.0:
                    chunk = chunk.sample(frac=sample_frac, random_state=42)

                if len(chunk) > 0:
                    file_chunks.append(chunk)

            if file_chunks:
                file_df = pd.concat(file_chunks, ignore_index=True)
                dfs.append(file_df)
                print(f"  âœ“ {file_path}: {len(file_df):,} è¡Œ")

        df = pd.concat(dfs, ignore_index=True)
        print(f"âœ… æ€»æ•°æ®é‡: {len(df):,} è¡Œ")

        # é¢„å¤„ç†
        df["datetime"] = pd.to_datetime(df["time"], format="%Y-%m-%d %H", errors="coerce")
        df = df.dropna(subset=["user_id", "item_id", "datetime"])
        df["user_id"] = df["user_id"].astype(np.int32)
        df["item_id"] = df["item_id"].astype(np.int32)

        return df

    def build_basic_features(self, df):
        """æ„å»ºåŸºç¡€ç”¨æˆ·ç‰¹å¾"""
        print("ğŸ”§ æ„å»ºåŸºç¡€ç”¨æˆ·ç‰¹å¾...")

        user_features = {}

        for user_id in tqdm(df["user_id"].unique(), desc="ğŸ“Š åŸºç¡€ç‰¹å¾"):
            user_data = df[df["user_id"] == user_id]

            # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
            features = {
                # æ´»è·ƒåº¦ç‰¹å¾
                "total_actions": len(user_data),
                "unique_items": user_data["item_id"].nunique(),
                "unique_categories": user_data["item_category"].nunique(),
                "active_days": user_data["datetime"].dt.date.nunique(),

                # è¡Œä¸ºæ¨¡å¼ç‰¹å¾
                "browse_count": len(user_data[user_data["behavior_type"] == 1]),
                "collect_count": len(user_data[user_data["behavior_type"] == 2]),
                "cart_count": len(user_data[user_data["behavior_type"] == 3]),
                "purchase_count": len(user_data[user_data["behavior_type"] == 4]),

                # è½¬åŒ–ç‡ç‰¹å¾
                "collect_rate": len(user_data[user_data["behavior_type"] == 2]) / max(len(user_data[user_data["behavior_type"] == 1]), 1),
                "cart_rate": len(user_data[user_data["behavior_type"] == 3]) / max(len(user_data[user_data["behavior_type"] == 1]), 1),
                "purchase_rate": len(user_data[user_data["behavior_type"] == 4]) / max(len(user_data[user_data["behavior_type"] == 1]), 1),

                # æ—¶é—´ç‰¹å¾
                "avg_hour": user_data["datetime"].dt.hour.mean(),
                "weekend_rate": (user_data["datetime"].dt.weekday >= 5).mean(),
                "last_action_days_ago": (pd.to_datetime(self.target_date) - user_data["datetime"].max()).days,
            }

            user_features[user_id] = features

        self.features.update(user_features)
        return user_features

    def build_geo_features(self, df):
        """æ„å»ºåœ°ç†ä½ç½®ç‰¹å¾"""
        print("ğŸŒ æ„å»ºåœ°ç†ä½ç½®ç‰¹å¾...")

        # åœ°ç†ä½ç½®è´­ä¹°åŠ›åˆ†æ
        geo_purchase_power = df[df["behavior_type"] == 4].groupby("user_geohash").size()
        geo_power_rank = geo_purchase_power.rank(pct=True)

        for user_id in tqdm(df["user_id"].unique(), desc="ğŸ“ åœ°ç†ç‰¹å¾"):
            user_data = df[df["user_id"] == user_id]

            # åœ°ç†ç‰¹å¾
            geo_features = {
                "unique_locations": user_data["user_geohash"].nunique(),
                "primary_location": user_data["user_geohash"].mode().iloc[0] if len(user_data["user_geohash"].mode()) > 0 else "unknown",
            }

            # ä¸»è¦åœ°ç†ä½ç½®çš„è´­ä¹°åŠ›
            primary_geo = geo_features["primary_location"]
            geo_features["location_purchase_power"] = geo_power_rank.get(primary_geo, 0.1)

            self.features[user_id].update(geo_features)

    def build_category_preferences(self, df):
        """æ„å»ºç±»åˆ«åå¥½ç‰¹å¾"""
        print("ğŸ·ï¸ æ„å»ºç±»åˆ«åå¥½ç‰¹å¾...")

        # å…¨å±€ç±»åˆ«çƒ­åº¦
        global_category_popularity = df.groupby("item_category").size()

        for user_id in tqdm(df["user_id"].unique(), desc="ğŸ¯ åå¥½ç‰¹å¾"):
            user_data = df[df["user_id"] == user_id]

            # ç±»åˆ«åå¥½ç‰¹å¾
            user_categories = user_data["item_category"].value_counts()

            category_features = {
                "top_category": user_categories.index[0] if len(user_categories) > 0 else -1,
                "category_concentration": (user_categories.iloc[0] / len(user_data)) if len(user_categories) > 0 else 0,
                "category_diversity": len(user_categories),
            }

            # åå¥½çƒ­é—¨ç¨‹åº¦
            if len(user_categories) > 0:
                top_cat_popularity = global_category_popularity.get(user_categories.index[0], 1)
                category_features["prefers_popular_categories"] = top_cat_popularity / global_category_popularity.max()
            else:
                category_features["prefers_popular_categories"] = 0

            self.features[user_id].update(category_features)

    def build_temporal_features(self, df):
        """æ„å»ºæ—¶é—´åºåˆ—ç‰¹å¾"""
        print("â° æ„å»ºæ—¶é—´åºåˆ—ç‰¹å¾...")

        for user_id in tqdm(df["user_id"].unique(), desc="ğŸ“ˆ æ—¶åºç‰¹å¾"):
            user_data = df[df["user_id"] == user_id].sort_values("datetime")

            # æ—¶é—´åºåˆ—ç‰¹å¾
            temporal_features = {
                "action_frequency": len(user_data) / max(user_data["datetime"].dt.date.nunique(), 1),
                "morning_rate": (user_data["datetime"].dt.hour < 12).mean(),
                "evening_rate": (user_data["datetime"].dt.hour >= 18).mean(),
            }

            # è¡Œä¸ºé—´éš”åˆ†æ
            if len(user_data) > 1:
                time_diffs = user_data["datetime"].diff().dt.total_seconds() / 3600  # å°æ—¶
                temporal_features.update({
                    "avg_action_interval_hours": time_diffs.mean(),
                    "action_regularity": 1 / (time_diffs.std() + 1),  # è§„å¾‹æ€§
                })
            else:
                temporal_features.update({
                    "avg_action_interval_hours": 24,
                    "action_regularity": 0,
                })

            self.features[user_id].update(temporal_features)

    def build_target_labels(self, df):
        """æ„å»ºç›®æ ‡æ ‡ç­¾ - é¢„æµ‹19æ—¥æ˜¯å¦è´­ä¹°"""
        print("ğŸ¯ æ„å»ºç›®æ ‡æ ‡ç­¾...")

        # åŠ è½½19æ—¥æ•°æ® (å¦‚æœæœ‰çš„è¯ï¼Œè¿™é‡Œå…ˆå‡è®¾æ²¡æœ‰)
        # å®é™…ä¸­æˆ‘ä»¬éœ€è¦é¢„æµ‹ï¼Œæ‰€ä»¥è¿™é‡Œæ„å»ºä¼ªæ ‡ç­¾ç”¨äºéªŒè¯

        for user_id in self.features.keys():
            user_data = df[df["user_id"] == user_id]

            # åŸºäºå†å²è¡Œä¸ºé¢„æµ‹è´­ä¹°æ¦‚ç‡ (ä¼ªæ ‡ç­¾)
            purchase_count = len(user_data[user_data["behavior_type"] == 4])
            recent_activity = len(user_data[user_data["datetime"] >= (pd.to_datetime(self.target_date) - pd.Timedelta(days=2))])

            # ç®€å•çš„å¯å‘å¼æ ‡ç­¾
            will_purchase = (purchase_count > 0 and recent_activity > 2) or (purchase_count > 2)

            self.features[user_id]["target_will_purchase"] = int(will_purchase)

    def export_features(self, filename="user_features.csv"):
        """å¯¼å‡ºç‰¹å¾æ•°æ®é›†"""
        print(f"ğŸ’¾ å¯¼å‡ºç‰¹å¾æ•°æ®é›†: {filename}")

        # è½¬æ¢ä¸ºDataFrame
        feature_df = pd.DataFrame.from_dict(self.features, orient="index")
        feature_df.index.name = "user_id"
        feature_df = feature_df.reset_index()

        # ä¿å­˜
        feature_df.to_csv(filename, index=False)

        print(f"âœ… ç‰¹å¾æ•°æ®é›†å·²ä¿å­˜")
        print(f"  ğŸ‘¥ ç”¨æˆ·æ•°: {len(feature_df):,}")
        print(f"  ğŸ”§ ç‰¹å¾æ•°: {len(feature_df.columns)-1}")
        print(f"  ğŸ¯ ç›®æ ‡æ¯”ä¾‹: {feature_df['target_will_purchase'].mean():.3f}")

        return feature_df


def main():
    """ä¸»å‡½æ•°"""
    print("=== ç”¨æˆ·ç‰¹å¾å·¥ç¨‹å™¨ ===")

    builder = UserFeatureBuilder(time_window_days=7)

    # 1. åŠ è½½æ•°æ® (ä½¿ç”¨é‡‡æ ·)
    df = builder.load_data(sample_frac=0.05)  # 5%é‡‡æ ·å¼€å§‹æµ‹è¯•

    # 2. æ„å»ºå„ç±»ç‰¹å¾
    builder.build_basic_features(df)
    builder.build_geo_features(df)
    builder.build_category_preferences(df)
    builder.build_temporal_features(df)
    builder.build_target_labels(df)

    # 3. å¯¼å‡ºç‰¹å¾
    feature_df = builder.export_features("user_features.csv")

    print("\nğŸ‰ ç”¨æˆ·ç‰¹å¾å·¥ç¨‹å®Œæˆ!")
    print("ä¸‹ä¸€æ­¥å¯ä»¥ä½¿ç”¨è¿™ä¸ªç‰¹å¾æ•°æ®é›†è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹")


if __name__ == "__main__":
    main()