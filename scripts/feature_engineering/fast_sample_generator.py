#!/usr/bin/env python3
"""
å¿«é€Ÿè®­ç»ƒæ ·æœ¬ç”Ÿæˆå™¨
åŸºäºç°æœ‰39ç»´ç”¨æˆ·ç‰¹å¾ + ç®€åŒ–å•†å“ç‰¹å¾ + æ ¸å¿ƒäº¤äº’ç‰¹å¾
"""

import sys
import pandas as pd
import numpy as np
from collections import defaultdict
import os
from tqdm import tqdm
import random
import warnings
warnings.filterwarnings('ignore')

sys.path.append('src')


class FastSampleGenerator:
    """å¿«é€Ÿè®­ç»ƒæ ·æœ¬ç”Ÿæˆå™¨"""

    def __init__(self, feature_dir="/mnt/data/tianchi_features",
                 data_dir="dataset/preprocess_16to18",
                 output_dir="/mnt/data/tianchi_features"):
        self.feature_dir = feature_dir
        self.data_dir = data_dir
        self.output_dir = output_dir

        # æ ¸å¿ƒäº¤äº’æ•°æ®ï¼ˆç®€åŒ–ï¼‰
        self.user_item_interactions = defaultdict(set)  # åªè®°å½•æ˜¯å¦æœ‰äº¤äº’
        self.user_purchases = defaultdict(set)  # åªè®°å½•è´­ä¹°

        print(f"ğŸ“ ç‰¹å¾ç›®å½•: {feature_dir}")

    def load_existing_features(self):
        """åŠ è½½ç°æœ‰ç‰¹å¾"""
        print("ğŸ“‚ åŠ è½½ç°æœ‰ç‰¹å¾...")

        # åŠ è½½39ç»´ç”¨æˆ·ç‰¹å¾
        user_file = os.path.join(self.feature_dir, "user_features_cpp.csv")
        if not os.path.exists(user_file):
            print(f"âŒ ç”¨æˆ·ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {user_file}")
            return False

        self.user_features = pd.read_csv(user_file)
        self.user_ids = set(self.user_features['user_id'].tolist())
        print(f"  ğŸ‘¥ ç”¨æˆ·ç‰¹å¾: {len(self.user_features):,} ç”¨æˆ·, 39ç»´")

        # åŠ è½½ç®€åŒ–å•†å“ç‰¹å¾
        item_file = os.path.join(self.feature_dir, "simple_item_features.csv")
        if not os.path.exists(item_file):
            print(f"âš ï¸  ç®€åŒ–å•†å“ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†å…ˆç”Ÿæˆ...")
            # è°ƒç”¨ç®€åŒ–å•†å“ç‰¹å¾ç”Ÿæˆ
            from simple_item_features import SimpleItemFeatureExtractor
            extractor = SimpleItemFeatureExtractor()
            extractor.load_item_catalog()
            extractor.process_data_files()
            extractor.export_features()

        self.item_features = pd.read_csv(item_file)
        self.item_ids = set(self.item_features['item_id'].tolist())
        print(f"  ğŸ“¦ å•†å“ç‰¹å¾: {len(self.item_features):,} å•†å“, {len(self.item_features.columns)-1}ç»´")

        # è½¬æ¢ä¸ºå­—å…¸
        self.user_feature_dict = self.user_features.set_index('user_id').to_dict('index')
        self.item_feature_dict = self.item_features.set_index('item_id').to_dict('index')

        return True

    def extract_core_interactions(self):
        """å¿«é€Ÿæå–æ ¸å¿ƒäº¤äº’ä¿¡æ¯"""
        print("\nğŸ“Š æå–æ ¸å¿ƒäº¤äº’ä¿¡æ¯...")

        # åªå¤„ç†18å·æ•°æ®æ¥ç”Ÿæˆæ­£æ ·æœ¬ï¼Œ16-17å·æ•°æ®æå–äº¤äº’å†å²
        data_files = [
            ("data_1216.txt", "å†å²äº¤äº’"),
            ("data_1217.txt", "å†å²äº¤äº’"),
            ("data_1218.txt", "æ ‡ç­¾ç”Ÿæˆ")
        ]

        columns = ["user_id", "item_id", "behavior_type", "user_geohash", "item_category", "time"]

        for filename, purpose in data_files:
            print(f"  ğŸ“… å¤„ç† {filename} ({purpose})")

            file_path = os.path.join(self.data_dir, filename)
            processed = 0

            for chunk in pd.read_csv(file_path, sep="\t", names=columns, chunksize=1000000):
                # è¿‡æ»¤ï¼šåªè¦æœ‰ç‰¹å¾çš„ç”¨æˆ·å’Œå•†å“
                chunk = chunk[chunk['user_id'].isin(self.user_ids)]
                chunk = chunk[chunk['item_id'].isin(self.item_ids)]

                if len(chunk) == 0:
                    continue

                for _, row in chunk.iterrows():
                    user_id = int(row['user_id'])
                    item_id = int(row['item_id'])
                    behavior = int(row['behavior_type'])

                    # è®°å½•äº¤äº’
                    self.user_item_interactions[user_id].add(item_id)

                    # è®°å½•è´­ä¹°ï¼ˆ18å·çš„ä½œä¸ºæ­£æ ·æœ¬æ ‡ç­¾ï¼‰
                    if behavior == 4 and filename == "data_1218.txt":
                        self.user_purchases[user_id].add(item_id)

                processed += len(chunk)

            print(f"    å¤„ç†äº† {processed:,} è¡Œ")

        interaction_pairs = sum(len(items) for items in self.user_item_interactions.values())
        purchase_pairs = sum(len(items) for items in self.user_purchases.values())

        print(f"  ğŸ“Š ç»Ÿè®¡:")
        print(f"    ç”¨æˆ·-å•†å“äº¤äº’å¯¹: {interaction_pairs:,}")
        print(f"    è´­ä¹°å¯¹ï¼ˆæ­£æ ·æœ¬ï¼‰: {purchase_pairs:,}")

    def generate_samples(self, max_negative_ratio=2):
        """å¿«é€Ÿç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
        print(f"\nğŸ”§ ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼ˆè´Ÿæ ·æœ¬æ¯”ä¾‹1:{max_negative_ratio}ï¼‰...")

        samples = []

        # 1. ç”Ÿæˆæ­£æ ·æœ¬
        print("  âœ… ç”Ÿæˆæ­£æ ·æœ¬...")
        positive_count = 0
        for user_id, purchased_items in tqdm(self.user_purchases.items(), desc="æ­£æ ·æœ¬"):
            for item_id in purchased_items:
                sample = self._create_sample(user_id, item_id, label=1)
                if sample:
                    samples.append(sample)
                    positive_count += 1

        print(f"    æ­£æ ·æœ¬æ•°: {positive_count:,}")

        # 2. ç”Ÿæˆè´Ÿæ ·æœ¬ï¼ˆç­–ç•¥ï¼šäº¤äº’æœªè´­ä¹°ï¼‰
        print("  âŒ ç”Ÿæˆè´Ÿæ ·æœ¬...")
        negative_count = 0
        target_negative = positive_count * max_negative_ratio

        for user_id, interacted_items in tqdm(self.user_item_interactions.items(), desc="è´Ÿæ ·æœ¬"):
            if negative_count >= target_negative:
                break

            purchased_items = self.user_purchases.get(user_id, set())

            # äº¤äº’ä½†æœªè´­ä¹°çš„å•†å“
            negative_items = interacted_items - purchased_items

            for item_id in negative_items:
                if negative_count >= target_negative:
                    break

                sample = self._create_sample(user_id, item_id, label=0)
                if sample:
                    samples.append(sample)
                    negative_count += 1

        print(f"    è´Ÿæ ·æœ¬æ•°: {negative_count:,}")

        # 3. éšæœºæ‰“ä¹±
        random.shuffle(samples)

        print(f"  ğŸ“Š æ€»æ ·æœ¬æ•°: {len(samples):,}")
        print(f"  ğŸ¯ æ­£æ ·æœ¬æ¯”ä¾‹: {positive_count/len(samples):.3f}")

        return pd.DataFrame(samples)

    def _create_sample(self, user_id, item_id, label):
        """åˆ›å»ºå•ä¸ªæ ·æœ¬ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
        if user_id not in self.user_feature_dict or item_id not in self.item_feature_dict:
            return None

        sample = {'user_id': user_id, 'item_id': item_id, 'label': label}

        # 39ç»´ç”¨æˆ·ç‰¹å¾
        user_features = self.user_feature_dict[user_id]
        for key, value in user_features.items():
            sample[f'user_{key}'] = value

        # ç®€åŒ–å•†å“ç‰¹å¾
        item_features = self.item_feature_dict[item_id]
        for key, value in item_features.items():
            if key != 'item_id':
                sample[f'item_{key}'] = value

        # æ ¸å¿ƒäº¤äº’ç‰¹å¾ï¼ˆåªä¿ç•™4ä¸ªæœ€é‡è¦çš„ï¼‰
        sample['has_interaction'] = 1 if item_id in self.user_item_interactions[user_id] else 0
        sample['has_purchased'] = 1 if item_id in self.user_purchases[user_id] else 0

        # ç”¨æˆ·å¯¹è¯¥ç±»åˆ«çš„åå¥½
        item_category = item_features.get('item_category', -1)
        user_top_category = user_features.get('top_category', -1)
        sample['category_match'] = 1 if item_category == user_top_category else 0

        # ç”¨æˆ·æ´»è·ƒåº¦ vs å•†å“æµè¡Œåº¦åŒ¹é…åº¦
        user_activity = user_features.get('total_actions', 0)
        item_popularity = item_features.get('popularity', 0)
        sample['activity_popularity_ratio'] = (user_activity + 1) / (item_popularity + 1)

        return sample

    def export_samples(self, samples_df):
        """å¯¼å‡ºè®­ç»ƒæ ·æœ¬"""
        print("\nğŸ’¾ å¯¼å‡ºè®­ç»ƒæ ·æœ¬...")

        # ä¿å­˜æ ·æœ¬
        output_file = os.path.join(self.output_dir, "fast_training_samples.csv")
        samples_df.to_csv(output_file, index=False)

        print(f"âœ… è®­ç»ƒæ ·æœ¬å·²ä¿å­˜: {output_file}")

        # ç‰¹å¾ç»Ÿè®¡
        feature_cols = [col for col in samples_df.columns if col not in ['user_id', 'item_id', 'label']]

        print(f"\nğŸ“‹ ç‰¹å¾åˆ†æ:")
        print(f"  ğŸ“ æ ·æœ¬æ•°: {len(samples_df):,}")
        print(f"  ğŸ”§ æ€»ç‰¹å¾æ•°: {len(feature_cols)}")
        print(f"  ğŸ‘¥ ç”¨æˆ·ç‰¹å¾: {len([col for col in feature_cols if col.startswith('user_')])}")
        print(f"  ğŸ“¦ å•†å“ç‰¹å¾: {len([col for col in feature_cols if col.startswith('item_')])}")
        print(f"  ğŸ”— äº¤äº’ç‰¹å¾: {len([col for col in feature_cols if col.startswith(('has_', 'category_', 'activity_'))])}")
        print(f"  ğŸ¯ æ­£æ ·æœ¬æ¯”ä¾‹: {samples_df['label'].mean():.3f}")

        # æ•°æ®è´¨é‡
        print(f"\nğŸ” æ•°æ®è´¨é‡:")
        print(f"  ğŸ“Š ç¼ºå¤±å€¼: {samples_df.isnull().sum().sum()}")
        print(f"  ğŸ“ˆ æ•°å€¼ç‰¹å¾æ•°: {len(samples_df.select_dtypes(include=[np.number]).columns)}")

        return output_file


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ === å¿«é€Ÿè®­ç»ƒæ ·æœ¬ç”Ÿæˆå™¨ === ğŸ”§")
    print("ğŸ¯ ç›®æ ‡ï¼šåŸºäºç°æœ‰39ç»´ç”¨æˆ·ç‰¹å¾å¿«é€Ÿç”Ÿæˆè®­ç»ƒæ ·æœ¬")
    print("âš¡ é¢„è®¡è€—æ—¶ï¼š3-4åˆ†é’Ÿ")
    print("â”" * 50)

    generator = FastSampleGenerator()

    # 1. åŠ è½½ç°æœ‰ç‰¹å¾
    if not generator.load_existing_features():
        print("âŒ ç‰¹å¾åŠ è½½å¤±è´¥")
        return

    # 2. æå–æ ¸å¿ƒäº¤äº’
    generator.extract_core_interactions()

    # 3. ç”Ÿæˆæ ·æœ¬
    samples_df = generator.generate_samples()

    # 4. å¯¼å‡ºæ ·æœ¬
    output_file = generator.export_samples(samples_df)

    print(f"\nğŸ‰ å¿«é€Ÿæ ·æœ¬ç”Ÿæˆå®Œæˆ!")
    print(f"âš¡ é€Ÿåº¦æå‡: æ¯”å®Œæ•´ç‰ˆæœ¬å¿«5-10å€")
    print(f"ğŸ“ è¾“å‡º: {output_file}")
    print(f"ğŸ¯ ç‰¹å¾æ€»æ•°: çº¦50ç»´ (39ç”¨æˆ· + 10å•†å“ + 4äº¤äº’)")


if __name__ == "__main__":
    main()