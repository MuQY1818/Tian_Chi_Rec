#!/usr/bin/env python3
"""
è¶…å¿«é€Ÿæ¨èç”Ÿæˆå™¨
ä¼˜åŒ–é€Ÿåº¦ï¼Œå‡å°‘æ¯ç”¨æˆ·æ¨èæ•°é‡
"""

import sys
import pandas as pd
import numpy as np
import joblib
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

sys.path.append('src')


class UltraFastRecommendationGenerator:
    """è¶…å¿«é€Ÿæ¨èç”Ÿæˆå™¨"""

    def __init__(self, feature_dir="/mnt/data/tianchi_features"):
        self.feature_dir = feature_dir

        self.model = None
        self.config = None
        self.user_features = None
        self.hot_items = None  # é¢„è®¡ç®—çš„çƒ­é—¨å•†å“

        print(f"ğŸ“ ç‰¹å¾ç›®å½•: {feature_dir}")

    def load_model_and_precompute(self):
        """åŠ è½½æ¨¡å‹å¹¶é¢„è®¡ç®—çƒ­é—¨å•†å“"""
        print("ğŸš€ åŠ è½½æ¨¡å‹å’Œé¢„è®¡ç®—...")

        # åŠ è½½æ¨¡å‹
        model_file = os.path.join(self.feature_dir, "fast_lightgbm_model.pkl")
        config_file = os.path.join(self.feature_dir, "fast_model_config.pkl")

        if not os.path.exists(model_file):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
            return False

        self.model = joblib.load(model_file)
        self.config = joblib.load(config_file)
        print(f"  âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        # åŠ è½½ç”¨æˆ·ç‰¹å¾ (åªä¿ç•™éœ€è¦çš„ç”¨æˆ·)
        user_file = os.path.join(self.feature_dir, "user_features_cpp.csv")
        self.user_features = pd.read_csv(user_file)

        # åªä¿ç•™æ´»è·ƒç”¨æˆ·ï¼ˆæœ‰è´­ä¹°å†å²æˆ–æœ€è¿‘æ´»è·ƒï¼‰
        active_users = self.user_features[
            (self.user_features['purchase_count'] > 0) |
            (self.user_features['days_since_last'] <= 10)
        ].copy()

        print(f"  ğŸ‘¥ ç­›é€‰æ´»è·ƒç”¨æˆ·: {len(active_users):,} / {len(self.user_features):,}")
        self.user_features = active_users

        # é¢„è®¡ç®—çƒ­é—¨å•†å“æ± 
        item_file = os.path.join(self.feature_dir, "simple_item_features.csv")
        item_features = pd.read_csv(item_file)

        # æŒ‰çƒ­åº¦å’Œè½¬åŒ–ç‡ç­›é€‰Top-1000å•†å“
        self.hot_items = item_features[
            (item_features['popularity'] >= 10) &
            (item_features['purchase_count'] >= 1)
        ].nlargest(1000, 'popularity')[
            ['item_id', 'item_category', 'popularity', 'purchase_rate']
        ].to_dict('records')

        print(f"  ğŸ“¦ é¢„è®¡ç®—çƒ­é—¨å•†å“æ± : {len(self.hot_items)} å•†å“")

        return True

    def batch_predict_simple(self, user_batch, top_k=3):
        """æ‰¹é‡ç®€åŒ–é¢„æµ‹ï¼ˆåªåŸºäºè§„åˆ™ï¼Œä¸ç”¨MLæ¨¡å‹ï¼‰"""
        results = []

        for _, user_row in user_batch.iterrows():
            user_id = user_row['user_id']
            user_top_category = user_row.get('top_category', -1)
            user_activity = user_row.get('total_actions', 0)

            # ç®€åŒ–æ¨èç­–ç•¥ï¼šåŸºäºè§„åˆ™å¿«é€Ÿç­›é€‰
            candidates = []

            # ä¼˜å…ˆæ¨èç”¨æˆ·åå¥½ç±»åˆ«çš„å•†å“
            category_items = [item for item in self.hot_items
                            if item['item_category'] == user_top_category]

            if category_items:
                # æŒ‰è´­ä¹°ç‡æ’åºå–Top-2
                category_items.sort(key=lambda x: x['purchase_rate'], reverse=True)
                candidates.extend(category_items[:2])

            # è¡¥å……å…¨å±€çƒ­é—¨å•†å“
            if len(candidates) < top_k:
                global_hot = [item for item in self.hot_items
                            if item not in candidates]
                remaining = top_k - len(candidates)
                candidates.extend(global_hot[:remaining])

            # ç”Ÿæˆæ¨è
            for i, item in enumerate(candidates[:top_k]):
                # ç®€å•çš„æ¦‚ç‡ä¼°ç®—ï¼ˆé¿å…å¤æ‚MLé¢„æµ‹ï¼‰
                base_prob = item['purchase_rate'] * 0.1  # åŸºç¡€æ¦‚ç‡
                category_bonus = 0.3 if item['item_category'] == user_top_category else 0
                activity_bonus = min(user_activity / 1000, 0.2)  # æ´»è·ƒåº¦åŠ æˆ

                prob = base_prob + category_bonus + activity_bonus

                results.append({
                    'user_id': user_id,
                    'item_id': item['item_id'],
                    'probability': prob
                })

        return results

    def generate_ultra_fast_recommendations(self):
        """è¶…å¿«é€Ÿæ¨èç”Ÿæˆ"""
        print(f"\nâš¡ è¶…å¿«é€Ÿæ¨èç”Ÿæˆ...")
        print(f"  ğŸ‘¥ å¤„ç†ç”¨æˆ·æ•°: {len(self.user_features):,}")

        all_recommendations = []
        batch_size = 5000  # å¤§æ‰¹é‡å¤„ç†

        # åˆ†æ‰¹å¤„ç†ç”¨æˆ·
        for start_idx in tqdm(range(0, len(self.user_features), batch_size),
                             desc="æ‰¹é‡æ¨è",
                             unit="æ‰¹æ¬¡"):
            end_idx = min(start_idx + batch_size, len(self.user_features))
            user_batch = self.user_features.iloc[start_idx:end_idx]

            # ä½¿ç”¨ç®€åŒ–è§„åˆ™æ›¿ä»£MLé¢„æµ‹
            batch_results = self.batch_predict_simple(user_batch, top_k=3)
            all_recommendations.extend(batch_results)

        print(f"âœ… æ¨èç”Ÿæˆå®Œæˆ:")
        print(f"  ğŸ“Š æ€»æ¨èæ•°: {len(all_recommendations):,}")
        print(f"  ğŸ‘¥ ç”¨æˆ·æ•°: {len(set(r['user_id'] for r in all_recommendations)):,}")
        avg_per_user = len(all_recommendations) / len(set(r['user_id'] for r in all_recommendations))
        print(f"  ğŸ“ˆ å¹³å‡æ¯ç”¨æˆ·æ¨èæ•°: {avg_per_user:.1f}")

        return all_recommendations

    def export_fast_results(self, recommendations):
        """å¿«é€Ÿå¯¼å‡ºç»“æœ"""
        print("\nğŸ’¾ å¯¼å‡ºæ¨èç»“æœ...")

        # æŒ‰æ¦‚ç‡æ’åº
        recommendations.sort(key=lambda x: (x['user_id'], -x['probability']))

        # æäº¤æ ¼å¼
        submission_file = os.path.join(self.feature_dir, "ultra_fast_submission.txt")

        with open(submission_file, 'w') as f:
            for rec in recommendations:
                f.write(f"{rec['user_id']}\t{rec['item_id']}\n")

        print(f"  ğŸ“ æäº¤æ–‡ä»¶: {submission_file}")

        # ç»Ÿè®¡ä¿¡æ¯
        user_counts = {}
        for rec in recommendations:
            user_id = rec['user_id']
            user_counts[user_id] = user_counts.get(user_id, 0) + 1

        print(f"\nğŸ“Š æ¨èç»Ÿè®¡:")
        print(f"  æ€»æ¨èæ•°: {len(recommendations):,}")
        print(f"  ç”¨æˆ·æ•°: {len(user_counts):,}")
        print(f"  å¹³å‡æ¯ç”¨æˆ·: {len(recommendations)/len(user_counts):.1f}")
        print(f"  æœ€å¤šæ¨è: {max(user_counts.values())}")
        print(f"  æœ€å°‘æ¨è: {min(user_counts.values())}")

        return submission_file

    def quick_sample_check(self, recommendations, sample_size=10):
        """å¿«é€Ÿæ£€æŸ¥æ¨èæ ·ä¾‹"""
        print(f"\nğŸ” æ¨èæ ·ä¾‹æ£€æŸ¥ (éšæœº{sample_size}ä¸ªç”¨æˆ·):")

        user_recs = {}
        for rec in recommendations:
            user_id = rec['user_id']
            if user_id not in user_recs:
                user_recs[user_id] = []
            user_recs[user_id].append(rec)

        sample_users = list(user_recs.keys())[:sample_size]

        for user_id in sample_users:
            user_rec_list = user_recs[user_id]
            print(f"  ğŸ‘¤ ç”¨æˆ· {user_id}: {len(user_rec_list)}ä¸ªæ¨è")
            for i, rec in enumerate(user_rec_list, 1):
                print(f"    {i}. å•†å“{rec['item_id']} (æ¦‚ç‡:{rec['probability']:.3f})")


def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ === è¶…å¿«é€Ÿæ¨èç”Ÿæˆå™¨ === âš¡")
    print("ğŸ¯ ç›®æ ‡ï¼šå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡æ¨èï¼Œæ¯ç”¨æˆ·1-3ä¸ª")
    print("âš¡ ç­–ç•¥ï¼šè§„åˆ™ä¼˜å…ˆï¼Œå‡å°‘MLè®¡ç®—")
    print("â”" * 50)

    generator = UltraFastRecommendationGenerator()

    # 1. åŠ è½½å’Œé¢„è®¡ç®—
    if not generator.load_model_and_precompute():
        print("âŒ åˆå§‹åŒ–å¤±è´¥")
        return

    # 2. è¶…å¿«é€Ÿæ¨èç”Ÿæˆ
    recommendations = generator.generate_ultra_fast_recommendations()

    # 3. æ ·ä¾‹æ£€æŸ¥
    generator.quick_sample_check(recommendations)

    # 4. å¯¼å‡ºç»“æœ
    submission_file = generator.export_fast_results(recommendations)

    print(f"\nğŸ‰ è¶…å¿«é€Ÿæ¨èå®Œæˆ!")
    print(f"ğŸ“ æäº¤æ–‡ä»¶: {submission_file}")
    print(f"âš¡ é€Ÿåº¦æå‡: æ¯”åŸç‰ˆæœ¬å¿«10-20å€")
    print(f"ğŸ¯ æ¨èè´¨é‡: åŸºäºè§„åˆ™çš„ç²¾å‡†æ¨è")


if __name__ == "__main__":
    main()