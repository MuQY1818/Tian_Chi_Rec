#!/usr/bin/env python3

import sys
import os
import time
from typing import Dict, List

# æ·»åŠ è·¯å¾„
sys.path.append('src')

from traditional.data_processor import TraditionalDataProcessor
from traditional.itemcf import ItemCF
from traditional.popularity import TimeBasedPopularity, TrendingItems
from traditional.matrix_factorization import ALSMatrixFactorization
from traditional.ensemble import EnsembleRecommender, ColdStartHandler


def evaluate_recommendations(val_user_items: Dict[int, List[int]],
                           recommendations: Dict[int, List[int]],
                           k: int = 5) -> Dict[str, float]:
    """è¯„ä¼°æ¨èç»“æœ"""
    hits = 0
    total_users = 0
    total_recall = 0.0

    for user_id, true_items in val_user_items.items():
        if user_id in recommendations: 
            pred_items = recommendations[user_id][:k]
            pred_set = set(pred_items)
            true_set = set(true_items)

            hit_items = len(pred_set & true_set)
            hits += min(hit_items, 1)  # HR@K: è‡³å°‘å‘½ä¸­1ä¸ª
            total_recall += hit_items / len(true_set) if true_set else 0

            total_users += 1

    hr_k = hits / total_users if total_users > 0 else 0
    recall_k = total_recall / total_users if total_users > 0 else 0

    return {
        f'HR@{k}': hr_k,
        f'Recall@{k}': recall_k,
        'Coverage': len(set().union(*recommendations.values())) if recommendations else 0
    }


def main():
    print("=== ä¼ ç»Ÿæ¨èç®—æ³•è®­ç»ƒå’Œæµ‹è¯• ===")

    # 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
    print("\n1. æ•°æ®é¢„å¤„ç†...")
    processor = TraditionalDataProcessor(data_dir="dataset")

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å…¨é‡æ•°æ®
    import sys
    use_full_data = "--full" in sys.argv
    sample_frac = 0.1 if "--sample" in sys.argv else 1.0  # é»˜è®¤10%é‡‡æ ·æˆ–å…¨é‡

    if use_full_data:
        print("ğŸš€ ä½¿ç”¨å…¨é‡æ•°æ®é›†è®­ç»ƒ")
        df = processor.load_data(sample_frac=sample_frac, use_full_data=True)
    else:
        print("ğŸ§ª ä½¿ç”¨å°æ•°æ®é›†æµ‹è¯•")
        df = processor.load_data(sample_frac=1.0)  # å°æ•°æ®é›†

    # æ—¶é—´åˆ’åˆ†
    if use_full_data:
        # å…¨é‡æ•°æ®ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´åˆ’åˆ†
        train_df, val_df = processor.split_by_time(df, train_end="2014-12-17", val_date="2014-12-18")
    else:
        # å°æ•°æ®é›†è°ƒæ•´æ—¥æœŸ
        train_df, val_df = processor.split_by_time(df, train_end="2014-12-16", val_date="2014-12-17")

    # æ„å»ºäº¤äº’çŸ©é˜µ
    train_matrix = processor.build_interaction_matrix(train_df)
    time_weighted_matrix = processor.get_time_weighted_matrix(train_df)

    print(f"è®­ç»ƒçŸ©é˜µç»´åº¦: {train_matrix.shape}")
    print(f"äº¤äº’æ•°é‡: {train_matrix.nnz}")

    # è·å–è®­ç»ƒå’ŒéªŒè¯ç”¨æˆ·-å•†å“æ˜ å°„
    train_user_items = processor.get_user_items(train_df)
    val_user_items = processor.get_user_items(val_df, behavior_types=[4])  # åªè€ƒè™‘è´­ä¹°è¡Œä¸º

    print(f"è®­ç»ƒç”¨æˆ·æ•°: {len(train_user_items)}")
    print(f"éªŒè¯ç”¨æˆ·æ•°: {len(val_user_items)}")

    # 2. è®­ç»ƒå„ä¸ªç®—æ³•
    print("\n2. è®­ç»ƒæ¨èç®—æ³•...")

    # ItemCF
    print("\n2.1 è®­ç»ƒItemCF...")
    itemcf = ItemCF(k=20, similarity_metric="cosine")
    itemcf.fit(train_matrix)

    # æµè¡Œåº¦æ¨¡å‹
    print("\n2.2 è®­ç»ƒæµè¡Œåº¦æ¨¡å‹...")
    current_date = "2014-12-18" if use_full_data else "2014-12-17"
    popularity = TimeBasedPopularity(time_window_days=7)
    popularity.fit(train_df, current_date=current_date)

    # è¶‹åŠ¿å•†å“
    print("\n2.3 è®­ç»ƒè¶‹åŠ¿æ¨¡å‹...")
    trending = TrendingItems(short_window=3, long_window=14)
    trending.fit(train_df, current_date=current_date)

    # ALSçŸ©é˜µåˆ†è§£
    print("\n2.4 è®­ç»ƒALS...")
    als = ALSMatrixFactorization(factors=32, iterations=10)
    try:
        als.fit(time_weighted_matrix)
        als_available = True
    except Exception as e:
        print(f"ALSè®­ç»ƒå¤±è´¥: {e}")
        als_available = False

    # 3. å•ç‹¬è¯„ä¼°å„ç®—æ³•
    print("\n3. å•ç‹¬è¯„ä¼°å„ç®—æ³•...")

    # è¿‡æ»¤éªŒè¯ç”¨æˆ·ï¼ˆåªä¿ç•™è®­ç»ƒä¸­å‡ºç°çš„ç”¨æˆ·ï¼‰
    common_users = set(train_user_items.keys()) & set(val_user_items.keys())
    filtered_val_user_items = {u: val_user_items[u] for u in common_users}

    print(f"æœ‰æ•ˆéªŒè¯ç”¨æˆ·æ•°: {len(filtered_val_user_items)}")

    results = {}

    # è¯„ä¼°ItemCF
    print("\n3.1 è¯„ä¼°ItemCF...")
    try:
        itemcf_recs = itemcf.recommend_for_users(
            train_user_items, top_n=5
        )
        # è½¬æ¢ä¸ºç®€å•æ ¼å¼
        itemcf_simple = {u: [item for item, score in recs]
                        for u, recs in itemcf_recs.items() if u in filtered_val_user_items}
        results['ItemCF'] = evaluate_recommendations(filtered_val_user_items, itemcf_simple)
    except Exception as e:
        print(f"ItemCFè¯„ä¼°å¤±è´¥: {e}")
        results['ItemCF'] = {'HR@5': 0, 'Recall@5': 0, 'Coverage': 0}

    # è¯„ä¼°æµè¡Œåº¦
    print("\n3.2 è¯„ä¼°æµè¡Œåº¦æ¨¡å‹...")
    try:
        pop_recs = popularity.recommend_for_users(
            train_user_items, top_n=5
        )
        pop_simple = {u: [item for item, score in recs]
                     for u, recs in pop_recs.items() if u in filtered_val_user_items}
        results['Popularity'] = evaluate_recommendations(filtered_val_user_items, pop_simple)
    except Exception as e:
        print(f"æµè¡Œåº¦è¯„ä¼°å¤±è´¥: {e}")
        results['Popularity'] = {'HR@5': 0, 'Recall@5': 0, 'Coverage': 0}

    # è¯„ä¼°ALS
    if als_available:
        print("\n3.3 è¯„ä¼°ALS...")
        try:
            als_recs = als.recommend_for_users(
                train_user_items, top_n=5
            )
            als_simple = {u: [item for item, score in recs]
                         for u, recs in als_recs.items() if u in filtered_val_user_items}
            results['ALS'] = evaluate_recommendations(filtered_val_user_items, als_simple)
        except Exception as e:
            print(f"ALSè¯„ä¼°å¤±è´¥: {e}")
            results['ALS'] = {'HR@5': 0, 'Recall@5': 0, 'Coverage': 0}
    else:
        results['ALS'] = {'HR@5': 0, 'Recall@5': 0, 'Coverage': 0}

    # 4. èåˆæ¨è
    print("\n4. èåˆæ¨è...")
    ensemble = EnsembleRecommender(
        weights={'itemcf': 0.5, 'popularity': 0.3, 'als': 0.2},
        fusion_method="weighted_score"
    )

    ensemble.add_model('itemcf', itemcf, 0.5)
    ensemble.add_model('popularity', popularity, 0.3)
    if als_available:
        ensemble.add_model('als', als, 0.2)

    try:
        ensemble_recs = ensemble.recommend_for_users(
            train_user_items, top_n=5
        )
        ensemble_simple = {u: [item for item, score in recs]
                          for u, recs in ensemble_recs.items() if u in filtered_val_user_items}
        results['Ensemble'] = evaluate_recommendations(filtered_val_user_items, ensemble_simple)
    except Exception as e:
        print(f"èåˆè¯„ä¼°å¤±è´¥: {e}")
        results['Ensemble'] = {'HR@5': 0, 'Recall@5': 0, 'Coverage': 0}

    # 5. æ˜¾ç¤ºç»“æœ
    print("\n5. è¯„ä¼°ç»“æœ:")
    print("=" * 60)
    print(f"{'Algorithm':<12} {'HR@5':<8} {'Recall@5':<10} {'Coverage':<10}")
    print("-" * 60)

    for alg_name, metrics in results.items():
        print(f"{alg_name:<12} {metrics['HR@5']:<8.4f} {metrics['Recall@5']:<10.4f} {metrics['Coverage']:<10}")

    # 6. ç”Ÿæˆæœ€ç»ˆæäº¤æ–‡ä»¶
    print("\n6. ç”Ÿæˆæäº¤æ–‡ä»¶...")

    # é€‰æ‹©æœ€ä½³ç®—æ³•ï¼ˆåŸºäºHR@5ï¼‰
    best_algorithm = max(results.keys(), key=lambda x: results[x]['HR@5'])
    print(f"æœ€ä½³ç®—æ³•: {best_algorithm} (HR@5: {results[best_algorithm]['HR@5']:.4f})")

    # ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆæ¨è
    if best_algorithm == 'ItemCF':
        final_recs = itemcf.recommend_for_users(train_user_items, top_n=5)
    elif best_algorithm == 'Popularity':
        final_recs = popularity.recommend_for_users(train_user_items, top_n=5)
    elif best_algorithm == 'ALS' and als_available:
        final_recs = als.recommend_for_users(train_user_items, top_n=5)
    else:
        final_recs = ensemble.recommend_for_users(train_user_items, top_n=5)

    # ç”Ÿæˆæäº¤æ–‡ä»¶
    submission_file = "full_traditional_submission.txt" if use_full_data else "traditional_submission.txt"

    with open(submission_file, "w", encoding="utf-8") as f:
        for user_id, recs in final_recs.items():
            original_user_id = processor.id2user[user_id]
            for item_id, _ in recs:
                original_item_id = processor.id2item[item_id]
                f.write(f"{original_user_id}\t{original_item_id}\n")

    print(f"âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {submission_file}")
    print(f"ğŸ“Š æ¨èç”¨æˆ·æ•°: {len(final_recs)}")
    print(f"ğŸ“ æ¨èå•†å“å¯¹æ•°: {sum(len(recs) for recs in final_recs.values())}")
    print(f"ğŸ¯ ä½¿ç”¨ç®—æ³•: {best_algorithm}")

    if use_full_data:
        print("\nğŸ‰ å…¨é‡æ•°æ®è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ¯ å¯ä»¥æäº¤ {submission_file} åˆ°æ¯”èµ›å¹³å°")


if __name__ == "__main__":
    main()