#!/usr/bin/env python3
"""
LightGBMæ¨¡å‹è®­ç»ƒå™¨
ç”¨äºç”¨æˆ·-å•†å“äº¤äº’é¢„æµ‹
"""

import sys
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score
import joblib
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

sys.path.append('src')


class LightGBMTrainer:
    """LightGBMè®­ç»ƒå™¨"""

    def __init__(self, feature_dir="/mnt/data/tianchi_features",
                 model_dir="/mnt/data/tianchi_features"):
        self.feature_dir = feature_dir
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)

        self.model = None
        self.feature_names = None

        print(f"ğŸ“ ç‰¹å¾ç›®å½•: {feature_dir}")
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {model_dir}")

    def load_training_data(self):
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        print("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")

        train_file = os.path.join(self.feature_dir, "training_samples.csv")
        if not os.path.exists(train_file):
            print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
            return None

        # åˆ†å—åŠ è½½å¤§æ–‡ä»¶
        print("  ğŸ“Š åˆ†ææ–‡ä»¶å¤§å°...")
        df_sample = pd.read_csv(train_file, nrows=1000)
        total_lines = sum(1 for _ in open(train_file)) - 1  # å‡å»å¤´éƒ¨
        print(f"  ğŸ“ æ€»æ ·æœ¬æ•°: {total_lines:,}")

        if total_lines > 5000000:  # è¶…è¿‡500ä¸‡è¡Œåˆ†å—åŠ è½½
            print("  ğŸ”„ åˆ†å—åŠ è½½å¤§æ–‡ä»¶...")
            chunks = []
            chunk_size = 1000000

            for chunk in tqdm(pd.read_csv(train_file, chunksize=chunk_size),
                            total=(total_lines // chunk_size) + 1,
                            desc="åŠ è½½æ•°æ®"):
                chunks.append(chunk)

            df = pd.concat(chunks, ignore_index=True)
        else:
            df = pd.read_csv(train_file)

        print(f"âœ… è®­ç»ƒæ•°æ®åŠ è½½å®Œæˆ:")
        print(f"  ğŸ“ æ ·æœ¬æ•°: {len(df):,}")
        print(f"  ğŸ”§ ç‰¹å¾æ•°: {len(df.columns)-3}")
        print(f"  ğŸ¯ æ­£æ ·æœ¬æ¯”ä¾‹: {df['label'].mean():.3f}")

        return df

    def prepare_features(self, df):
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        print("\nğŸ”§ å‡†å¤‡ç‰¹å¾æ•°æ®...")

        # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
        feature_cols = [col for col in df.columns if col not in ['user_id', 'item_id', 'label']]
        X = df[feature_cols]
        y = df['label']

        # ä¿å­˜ç‰¹å¾å
        self.feature_names = feature_cols

        print(f"  ğŸ”§ ç‰¹å¾ç»´åº¦: {X.shape}")
        print(f"  ğŸ¯ æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")

        # æ•°æ®è´¨é‡æ£€æŸ¥
        print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
        missing_cols = X.columns[X.isnull().any()].tolist()
        if missing_cols:
            print(f"  âš ï¸  æœ‰ç¼ºå¤±å€¼çš„åˆ—: {len(missing_cols)}")
            # ç®€å•å¡«å……ç¼ºå¤±å€¼
            X = X.fillna(0)
            print(f"  ğŸ”§ å·²ç”¨0å¡«å……ç¼ºå¤±å€¼")
        else:
            print(f"  âœ… æ— ç¼ºå¤±å€¼")

        # æ£€æŸ¥æ— ç©·å€¼
        inf_cols = X.columns[np.isinf(X).any()].tolist()
        if inf_cols:
            print(f"  âš ï¸  æœ‰æ— ç©·å€¼çš„åˆ—: {len(inf_cols)}")
            X = X.replace([np.inf, -np.inf], 0)
            print(f"  ğŸ”§ å·²ç”¨0æ›¿æ¢æ— ç©·å€¼")

        return X, y

    def split_data(self, X, y, test_size=0.2, random_state=42):
        """åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"""
        print(f"\nğŸ“Š åˆ’åˆ†æ•°æ®é›† (éªŒè¯é›†æ¯”ä¾‹: {test_size})...")

        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )

        print(f"  ğŸ“ˆ è®­ç»ƒé›†: {len(X_train):,} æ ·æœ¬, æ­£æ ·æœ¬ç‡: {y_train.mean():.3f}")
        print(f"  ğŸ“Š éªŒè¯é›†: {len(X_val):,} æ ·æœ¬, æ­£æ ·æœ¬ç‡: {y_val.mean():.3f}")

        return X_train, X_val, y_train, y_val

    def train_model(self, X_train, y_train, X_val, y_val):
        """è®­ç»ƒLightGBMæ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹...")

        # LightGBMå‚æ•°
        params = {
            'objective': 'binary',
            'metric': 'auc',
            'boosting_type': 'gbdt',
            'num_leaves': 127,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'min_child_samples': 20,
            'min_child_weight': 0.001,
            'min_split_gain': 0.0,
            'reg_alpha': 0.0,
            'reg_lambda': 0.0,
            'random_state': 42,
            'n_jobs': -1,
            'verbose': -1
        }

        print(f"ğŸ“‹ æ¨¡å‹å‚æ•°:")
        for key, value in params.items():
            print(f"  {key}: {value}")

        # å‡†å¤‡æ•°æ®é›†
        train_data = lgb.Dataset(X_train, label=y_train, feature_name=self.feature_names)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, feature_name=self.feature_names)

        # è®­ç»ƒæ¨¡å‹
        print(f"\nğŸ”„ å¼€å§‹è®­ç»ƒ...")
        self.model = lgb.train(
            params=params,
            train_set=train_data,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'eval'],
            num_boost_round=1000,
            callbacks=[
                lgb.early_stopping(stopping_rounds=50),
                lgb.log_evaluation(period=50)
            ]
        )

        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"  ğŸŒ³ æœ€ä½³è½®æ•°: {self.model.best_iteration}")

        return self.model

    def evaluate_model(self, X_val, y_val):
        """è¯„ä¼°æ¨¡å‹"""
        print("\nğŸ“Š æ¨¡å‹è¯„ä¼°...")

        # é¢„æµ‹
        y_pred_proba = self.model.predict(X_val, num_iteration=self.model.best_iteration)
        y_pred = (y_pred_proba > 0.5).astype(int)

        # AUC
        auc = roc_auc_score(y_val, y_pred_proba)
        print(f"  ğŸ“ˆ AUC: {auc:.4f}")

        # æ‰¾æœ€ä½³é˜ˆå€¼
        precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)
        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
        best_threshold_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_threshold_idx]
        best_f1 = f1_scores[best_threshold_idx]

        print(f"  ğŸ¯ æœ€ä½³é˜ˆå€¼: {best_threshold:.4f}")
        print(f"  ğŸ“Š æœ€ä½³F1: {best_f1:.4f}")

        # ä½¿ç”¨æœ€ä½³é˜ˆå€¼é‡æ–°é¢„æµ‹
        y_pred_best = (y_pred_proba > best_threshold).astype(int)
        precision_best = np.sum((y_pred_best == 1) & (y_val == 1)) / np.sum(y_pred_best == 1)
        recall_best = np.sum((y_pred_best == 1) & (y_val == 1)) / np.sum(y_val == 1)

        print(f"  âœ… æœ€ä½³é˜ˆå€¼ä¸‹:")
        print(f"    Precision: {precision_best:.4f}")
        print(f"    Recall: {recall_best:.4f}")

        return {
            'auc': auc,
            'best_threshold': best_threshold,
            'best_f1': best_f1,
            'precision': precision_best,
            'recall': recall_best
        }

    def analyze_feature_importance(self, top_n=20):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ (Top {top_n})...")

        importance = self.model.feature_importance(importance_type='gain')
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)

        print(f"ğŸ“Š Top {top_n} é‡è¦ç‰¹å¾:")
        for i, row in feature_importance.head(top_n).iterrows():
            print(f"  {row['feature']}: {row['importance']:.2f}")

        # æŒ‰ç‰¹å¾ç±»å‹åˆ†ç»„åˆ†æ
        user_features = feature_importance[feature_importance['feature'].str.startswith('user_')]
        item_features = feature_importance[feature_importance['feature'].str.startswith('item_')]
        interaction_features = feature_importance[feature_importance['feature'].str.startswith('interaction_')]

        print(f"\nğŸ“‹ ç‰¹å¾ç±»å‹é‡è¦æ€§:")
        print(f"  ğŸ‘¥ ç”¨æˆ·ç‰¹å¾å¹³å‡é‡è¦æ€§: {user_features['importance'].mean():.2f}")
        print(f"  ğŸ“¦ å•†å“ç‰¹å¾å¹³å‡é‡è¦æ€§: {item_features['importance'].mean():.2f}")
        print(f"  ğŸ”— äº¤äº’ç‰¹å¾å¹³å‡é‡è¦æ€§: {interaction_features['importance'].mean():.2f}")

        return feature_importance

    def save_model(self, metrics):
        """ä¿å­˜æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶"""
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")

        # ä¿å­˜æ¨¡å‹
        model_file = os.path.join(self.model_dir, "lightgbm_model.pkl")
        joblib.dump(self.model, model_file)
        print(f"  ğŸ“¦ æ¨¡å‹å·²ä¿å­˜: {model_file}")

        # ä¿å­˜ç‰¹å¾å
        feature_file = os.path.join(self.model_dir, "feature_names.pkl")
        joblib.dump(self.feature_names, feature_file)
        print(f"  ğŸ“ ç‰¹å¾åå·²ä¿å­˜: {feature_file}")

        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        metrics_file = os.path.join(self.model_dir, "model_metrics.pkl")
        joblib.dump(metrics, metrics_file)
        print(f"  ğŸ“Š æŒ‡æ ‡å·²ä¿å­˜: {metrics_file}")

        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        model_info = {
            'model_type': 'LightGBM',
            'feature_count': len(self.feature_names),
            'best_iteration': self.model.best_iteration,
            'auc': metrics['auc'],
            'best_f1': metrics['best_f1'],
            'best_threshold': metrics['best_threshold']
        }

        info_file = os.path.join(self.model_dir, "model_info.txt")
        with open(info_file, 'w') as f:
            f.write("=== LightGBMæ¨¡å‹ä¿¡æ¯ ===\n")
            for key, value in model_info.items():
                f.write(f"{key}: {value}\n")
        print(f"  ğŸ“‹ æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {info_file}")

        print(f"âœ… æ¨¡å‹ä¿å­˜å®Œæˆ!")

    def load_model(self):
        """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        print("ğŸ“‚ åŠ è½½å·²è®­ç»ƒæ¨¡å‹...")

        model_file = os.path.join(self.model_dir, "lightgbm_model.pkl")
        feature_file = os.path.join(self.model_dir, "feature_names.pkl")

        if os.path.exists(model_file) and os.path.exists(feature_file):
            self.model = joblib.load(model_file)
            self.feature_names = joblib.load(feature_file)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        else:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
            return False

    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡"""
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒæˆ–åŠ è½½")

        return self.model.predict(X, num_iteration=self.model.best_iteration)


def main():
    """ä¸»å‡½æ•°"""
    print("=== LightGBMæ¨¡å‹è®­ç»ƒå™¨ ===")
    print("ğŸ¯ ç›®æ ‡ï¼šè®­ç»ƒç”¨æˆ·-å•†å“äº¤äº’é¢„æµ‹æ¨¡å‹")

    trainer = LightGBMTrainer()

    # 1. åŠ è½½è®­ç»ƒæ•°æ®
    df = trainer.load_training_data()
    if df is None:
        return

    # 2. å‡†å¤‡ç‰¹å¾
    X, y = trainer.prepare_features(df)

    # 3. åˆ’åˆ†æ•°æ®
    X_train, X_val, y_train, y_val = trainer.split_data(X, y)

    # 4. è®­ç»ƒæ¨¡å‹
    model = trainer.train_model(X_train, y_train, X_val, y_val)

    # 5. è¯„ä¼°æ¨¡å‹
    metrics = trainer.evaluate_model(X_val, y_val)

    # 6. ç‰¹å¾é‡è¦æ€§åˆ†æ
    feature_importance = trainer.analyze_feature_importance()

    # 7. ä¿å­˜æ¨¡å‹
    trainer.save_model(metrics)

    print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ˆ æœ€ç»ˆAUC: {metrics['auc']:.4f}")
    print(f"ğŸ“Š æœ€ä½³F1: {metrics['best_f1']:.4f}")
    print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {trainer.model_dir}")
    print(f"ä¸‹ä¸€æ­¥ï¼šç”Ÿæˆæœ€ç»ˆæ¨è")


if __name__ == "__main__":
    main()