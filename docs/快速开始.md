# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ¯ æ¯”èµ›ç›®æ ‡
é¢„æµ‹ç”¨æˆ·åœ¨2014å¹´12æœˆ19æ—¥ä¼šè´­ä¹°å“ªäº›å•†å“ï¼Œè¾“å‡º`user_id\titem_id`å¯¹ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„
```
Tian_Chi_Rec/
â”œâ”€â”€ main_large_scale.py          # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ src/                        # æºä»£ç 
â”œâ”€â”€ config/                     # é…ç½®æ–‡ä»¶
â”œâ”€â”€ dataset/                    # åŸå§‹æ•°æ® (50GB)
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â””â”€â”€ submission.txt             # æœ€ç»ˆè¾“å‡º
```

## ğŸš€ ä¸€é”®è¿è¡Œ

### å®Œæ•´æµç¨‹ (æ¨è)
```bash
# è¿è¡Œå®Œæ•´çš„å¤§è§„æ¨¡æ¨èç³»ç»Ÿ
python main_large_scale.py --mode full --model_type ensemble
```

### åˆ†æ­¥è¿è¡Œ
```bash
# 1. æ•°æ®é¢„å¤„ç† (å¤„ç†50GBæ•°æ®)
python main_large_scale.py --mode preprocess

# 2. æ¨¡å‹è®­ç»ƒ (è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹)
python main_large_scale.py --mode train --model_type ensemble

# 3. ç”Ÿæˆæ¨è (åˆ›å»ºsubmission.txt)
python main_large_scale.py --mode predict --model_type ensemble
```

## ğŸ“Š æ•°æ®å‡†å¤‡

### åŸå§‹æ•°æ®
ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äº`dataset/`ç›®å½•ï¼š
- `tianchi_fresh_comp_train_item_online.txt` (114MB)
- `tianchi_fresh_comp_train_user_online_partA.txt` (26GB)  
- `tianchi_fresh_comp_train_user_online_partB.txt` (24.5GB)

### æ•°æ®è§„æ¨¡
- **æ€»æ•°æ®**: 50GB
- **ç”¨æˆ·è¡Œä¸º**: 11.65äº¿æ¡è®°å½•
- **å•†å“å­é›†**: 678ä¸‡å•†å“

## âš™ï¸ ç¯å¢ƒé…ç½®

### å®‰è£…ä¾èµ–
```bash
pip install -r config/requirements.txt
```

### ä¸»è¦ä¾èµ–
- **æ·±åº¦å­¦ä¹ **: tensorflow, torch, torch-geometric
- **å¤§æ•°æ®å¤„ç†**: dask[complete]
- **æœºå™¨å­¦ä¹ **: scikit-learn, xgboost
- **å·¥å…·åŒ…**: pandas, numpy, tqdm

## ğŸ”§ æ¨¡å‹é…ç½®

### å¯é€‰æ¨¡å‹
- `gru4rec`: GRUåºåˆ—æ¨èæ¨¡å‹
- `deepfm`: DeepFMç‰¹å¾äº¤å‰æ¨¡å‹  
- `ensemble`: å¤šæ¨¡å‹é›†æˆ (æ¨è)

### å‚æ•°è°ƒæ•´
```bash
# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
python main_large_scale.py --mode full --model_type ensemble --epochs 100 --batch_size 256
```

## ğŸ“ˆ é¢„æœŸç»“æœ

### æ¨¡å‹æ€§èƒ½
| æ¨¡å‹ | F1åˆ†æ•° | è®­ç»ƒæ—¶é—´ |
|------|--------|----------|
| GRU4Rec | 0.75+ | 2-4å°æ—¶ |
| DeepFM | 0.78+ | 1-3å°æ—¶ |
| é›†æˆæ¨¡å‹ | 0.82+ | 4-6å°æ—¶ |

### è¾“å‡ºæ–‡ä»¶
- `submission.txt`: æœ€ç»ˆæ¨èç»“æœ
- `models/`: è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶
- `logs/`: è®­ç»ƒæ—¥å¿—

## ğŸ¯ è¾“å‡ºæ ¼å¼

### submission.txt
```
user_id    item_id
1001      123456
1001      789012
1002      345678
...
```

### è¾“å‡ºè¦æ±‚
- **æ ¼å¼**: tabåˆ†éš”ï¼Œæ— è¡¨å¤´
- **æ’åº**: user_idå‡åº
- **æ•°é‡**: æ¯ä¸ªç”¨æˆ·æœ€å¤š5ä¸ªå•†å“
- **å•†å“**: å¿…é¡»æ¥è‡ªå•†å“å­é›†

## ğŸ” å¸¸è§é—®é¢˜

### Q: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: ç³»ç»Ÿä½¿ç”¨Daskåˆ†å¸ƒå¼å¤„ç†ï¼Œæ”¯æŒåˆ†å—åŠ è½½ï¼Œå†…å­˜éœ€æ±‚<32GB

### Q: è®­ç»ƒæ—¶é—´å¤ªé•¿ï¼Ÿ
A: å¯ä»¥å‡å°‘epochsæˆ–ä½¿ç”¨è¾ƒå°çš„batch_size

### Q: åªæƒ³å¿«é€Ÿæµ‹è¯•ï¼Ÿ
A: ä½¿ç”¨ä¼ ç»Ÿæ¨¡å‹ï¼š`python src/models/simple_baseline_models.py`

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ç³»ç»Ÿæ¶æ„](ç³»ç»Ÿæ¶æ„.md): è¯¦ç»†æŠ€æœ¯æ¶æ„
- [æ¨¡å‹è¯´æ˜](æ¨¡å‹è¯´æ˜.md): æ¨¡å‹åŸç†è¯¦è§£
- [é…ç½®è¯´æ˜](../config/config.py): å‚æ•°é…ç½®è¯´æ˜

## ğŸš€ å¼€å§‹æ¯”èµ›

```bash
# 1. ç¡®ä¿æ•°æ®å°±ç»ª
ls -la dataset/

# 2. å®‰è£…ä¾èµ–
pip install -r config/requirements.txt

# 3. è¿è¡Œç³»ç»Ÿ
python main_large_scale.py --mode full --model_type ensemble

# 4. æŸ¥çœ‹ç»“æœ
head -n 10 submission.txt
```

## ğŸ¯ é¢„æœŸæ•ˆæœ

ä½¿ç”¨å®Œæ•´çš„æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿï¼Œé¢„æœŸF1åˆ†æ•°å¯è¾¾0.82+ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹ç”¨æˆ·è´­ä¹°è¡Œä¸ºå¹¶ç”Ÿæˆé«˜è´¨é‡çš„æ¨èç»“æœã€‚